{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch a Build: Only Estimate Reports \n",
    "# For Avnet Ultra96-v2 Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9821767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"finn_lenet.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_estimates_only\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xczu3eg-sbva484-1-i\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e352a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from finn_lenet.onnx\n",
      "Intermediate outputs will be generated in /home/rstar900/finn/my_builds\n",
      "Final outputs will be generated in output_estimates_only\n",
      "Build log is at output_estimates_only/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/8]\n",
      "Running step: step_tidy_up [2/8]\n",
      "Running step: step_streamline [3/8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rstar900/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:93: UserWarning: Some old-style domain attributes were automatically converted to new-style,\n",
      "                i.e. domain=finn to domain=qonnx.custom_op.<general|fpgadataflow|...>\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step: step_convert_to_hls [4/8]\n",
      "Running step: step_create_dataflow_partition [5/8]\n",
      "Running step: step_target_fps_parallelization [6/8]\n",
      "Running step: step_apply_folding_config [7/8]\n",
      "Running step: step_generate_estimate_reports [8/8]\n",
      "Completed successfully\n",
      "CPU times: user 1.82 s, sys: 0 ns, total: 1.82 s\n",
      "Wall time: 1.68 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bad157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll now examine the generated outputs from this build\n",
    "# If we look under the outputs directory, we'll find a subfolder with the generated estimate reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517d7845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_folding_config.json  intermediate_models  time_per_step.json\r\n",
      "build_dataflow.log\t  report\r\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a85fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_config_alternatives.json  estimate_network_performance.json\r\n",
      "estimate_layer_cycles.json\t\t op_and_param_counts.json\r\n",
      "estimate_layer_resources.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed22d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"critical_path_cycles\": 89317,\r\n",
      "  \"max_cycles\": 19760,\r\n",
      "  \"max_cycles_node_name\": \"ConvolutionInputGenerator_0\",\r\n",
      "  \"estimated_throughput_fps\": 5060.728744939272,\r\n",
      "  \"estimated_latency_ns\": 893170.0\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "#  Let's examine the contents of the estimate_network_performance.json for starters. \n",
    "# Here, we can see the analytical estimates for the performance and latency\n",
    "! cat {estimates_output_dir}/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da524668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvolutionInputGenerator_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 372,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_0': {'BRAM_18K': 3,\n",
       "  'BRAM_efficiency': 0.0244140625,\n",
       "  'LUT': 1732,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_Batch_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 348,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_1': {'BRAM_18K': 2,\n",
       "  'BRAM_efficiency': 0.1953125,\n",
       "  'LUT': 1381,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_Batch_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_2': {'BRAM_18K': 12,\n",
       "  'BRAM_efficiency': 0.6510416666666666,\n",
       "  'LUT': 1255,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_3': {'BRAM_18K': 3,\n",
       "  'BRAM_efficiency': 0.546875,\n",
       "  'LUT': 1039,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_4': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.13671875,\n",
       "  'LUT': 346,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'total': {'BRAM_18K': 21.0, 'LUT': 6473.0, 'URAM': 0.0, 'DSP': 0.0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the layer-by-layer resource estimates in the estimate_layer_resources.json report \n",
    "# We can see if the layers will fit our FPGA using this report, if too high, consider lowering target_fps\n",
    "import json\n",
    "def read_json_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        ret = json.load(f)\n",
    "    return ret\n",
    "\n",
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2741d849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvolutionInputGenerator_0': 19760,\n",
       " 'MatrixVectorActivation_0': 14112,\n",
       " 'StreamingMaxPool_Batch_0': 980,\n",
       " 'ConvolutionInputGenerator_1': 15420,\n",
       " 'MatrixVectorActivation_1': 16000,\n",
       " 'StreamingMaxPool_Batch_1': 125,\n",
       " 'MatrixVectorActivation_2': 12000,\n",
       " 'MatrixVectorActivation_3': 10080,\n",
       " 'MatrixVectorActivation_4': 840}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at estimate_layer_cycles.json\n",
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_cycles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6014fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfaf4888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.24.0\r\n"
     ]
    }
   ],
   "source": [
    "# Check numpy version (should be 1.22.0)\n",
    "! pip freeze | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c442449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.24.0\n",
      "Uninstalling numpy-1.24.0:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/shutil.py\", line 788, in move\n",
      "    os.rename(src, real_dst)\n",
      "PermissionError: [Errno 13] Permission denied: '/opt/conda/bin/f2py' -> '/tmp/pip-uninstall-jjk3r_5y/f2py'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 228, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/commands/uninstall.py\", line 89, in run\n",
      "    uninstall_pathset = req.uninstall(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/req/req_install.py\", line 686, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/req/req_uninstall.py\", line 394, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/req/req_uninstall.py\", line 283, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/utils/misc.py\", line 352, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/opt/conda/lib/python3.8/shutil.py\", line 803, in move\n",
      "    os.unlink(src)\n",
      "PermissionError: [Errno 13] Permission denied: '/opt/conda/bin/f2py'\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.22.0\n",
      "  Downloading numpy-1.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.22.0\n"
     ]
    }
   ],
   "source": [
    "# if it is not, then run this cell\n",
    "! pip uninstall numpy -y\n",
    "! pip install numpy==1.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e29678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.22.0\r\n"
     ]
    }
   ],
   "source": [
    "# Check numpy version again (should be 1.22.0)\n",
    "! pip freeze | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b785e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"finn_lenet.onnx\"\n",
    "\n",
    "rtlsim_output_dir = \"output_ipstitch_ooc_rtlsim\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(rtlsim_output_dir):\n",
    "    shutil.rmtree(rtlsim_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "cfg_stitched_ip = build.DataflowBuildConfig(\n",
    "    output_dir          = rtlsim_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xczu3eg-sbva484-1-i\",\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee1366f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from finn_lenet.onnx\n",
      "Intermediate outputs will be generated in /home/rstar900/finn/my_builds\n",
      "Final outputs will be generated in output_ipstitch_ooc_rtlsim\n",
      "Build log is at output_ipstitch_ooc_rtlsim/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/17]\n",
      "Running step: step_tidy_up [2/17]\n",
      "Running step: step_streamline [3/17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rstar900/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:93: UserWarning: Some old-style domain attributes were automatically converted to new-style,\n",
      "                i.e. domain=finn to domain=qonnx.custom_op.<general|fpgadataflow|...>\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step: step_convert_to_hls [4/17]\n",
      "Running step: step_create_dataflow_partition [5/17]\n",
      "Running step: step_target_fps_parallelization [6/17]\n",
      "Running step: step_apply_folding_config [7/17]\n",
      "Running step: step_generate_estimate_reports [8/17]\n",
      "Running step: step_hls_codegen [9/17]\n",
      "Running step: step_hls_ipgen [10/17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/rstar900/finn/src/finn/builder/build_dataflow.py\", line 166, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/home/rstar900/finn/src/finn/builder/build_dataflow_steps.py\", line 460, in step_set_fifo_depths\n",
      "    model = model.transform(\n",
      "  File \"/home/rstar900/finn/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 140, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/rstar900/finn/src/finn/transformation/fpgadataflow/set_fifo_depths.py\", line 264, in apply\n",
      "    model = model.transform(InsertFIFO())\n",
      "  File \"/home/rstar900/finn/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 140, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/rstar900/finn/src/finn/transformation/fpgadataflow/insert_fifo.py\", line 113, in apply\n",
      "    fld_shape_2 = n1.get_folded_input_shape()\n",
      "  File \"/home/rstar900/finn/src/finn/custom_op/fpgadataflow/streamingdatawidthconverter_batch.py\", line 101, in get_folded_input_shape\n",
      "    self.check_divisible_iowidths()\n",
      "  File \"/home/rstar900/finn/src/finn/custom_op/fpgadataflow/streamingdatawidthconverter_batch.py\", line 94, in check_divisible_iowidths\n",
      "    assert (\n",
      "AssertionError: DWC OutWidth is bigger than InWidth and is not divisible by it.\n",
      "                Please adjust PE and SIMD values so that OutWidth % InWidth = 0\n",
      "                or alternatively use impl_style = vivado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step: step_set_fifo_depths [11/17]\n",
      "> \u001b[0;32m/home/rstar900/finn/src/finn/custom_op/fpgadataflow/streamingdatawidthconverter_batch.py\u001b[0m(94)\u001b[0;36mcheck_divisible_iowidths\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     92 \u001b[0;31m                or alternatively use impl_style = vivado\"\"\"\n",
      "\u001b[0m\u001b[0;32m     93 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 94 \u001b[0;31m                assert (\n",
      "\u001b[0m\u001b[0;32m     95 \u001b[0;31m                    \u001b[0mowidth\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miwidth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     96 \u001b[0;31m                ), \"\"\"DWC OutWidth is bigger than InWidth and is not divisible by it.\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "Build failed\n",
      "CPU times: user 8.22 s, sys: 234 ms, total: 8.45 s\n",
      "Wall time: 3min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_stitched_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab7bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-12-21 14:12:44,286] Running step: step_qonnx_to_finn [1/17]\r\n",
      "[2022-12-21 14:12:44,288] Running step: step_tidy_up [2/17]\r\n",
      "[2022-12-21 14:12:44,381] Running step: step_streamline [3/17]\r\n",
      "[2022-12-21 14:12:45,797] /home/rstar900/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:119: UserWarning: Assuming 4D input is NCHW\r\n",
      "[2022-12-21 14:12:45,797]   warnings.warn(\"Assuming 4D input is NCHW\")\r\n",
      "[2022-12-21 14:12:45,802] Running step: step_convert_to_hls [4/17]\r\n",
      "[2022-12-21 14:12:45,898] Running step: step_create_dataflow_partition [5/17]\r\n",
      "[2022-12-21 14:12:45,904] Running step: step_target_fps_parallelization [6/17]\r\n",
      "[2022-12-21 14:12:45,906] /home/rstar900/finn/src/finn/transformation/fpgadataflow/set_folding.py:189: UserWarning: SetFolding doesn't know how to handle op_type StreamingMaxPool_Batch\r\n",
      "[2022-12-21 14:12:45,906]   warnings.warn(\r\n",
      "[2022-12-21 14:12:45,915] /home/rstar900/finn/src/finn/custom_op/fpgadataflow/streamingmaxpool_batch.py:142: UserWarning: Estimated latency for layer StreamingMaxPool_Batch_0 can be lower than\r\n",
      "[2022-12-21 14:12:45,915]              actual latency!\r\n",
      "[2022-12-21 14:12:45,915]   warnings.warn(\r\n",
      "[2022-12-21 14:12:45,916] /home/rstar900/finn/src/finn/custom_op/fpgadataflow/streamingmaxpool_batch.py:142: UserWarning: Estimated latency for layer StreamingMaxPool_Batch_1 can be lower than\r\n",
      "[2022-12-21 14:12:45,916]              actual latency!\r\n",
      "[2022-12-21 14:12:45,916]   warnings.warn(\r\n",
      "[2022-12-21 14:12:45,917] /home/rstar900/finn/src/finn/transformation/fpgadataflow/set_folding.py:203: UserWarning: Node ConvolutionInputGenerator_0 is bottleneck with 19760 cycles, running second pass\r\n",
      "[2022-12-21 14:12:45,917]   warnings.warn(\r\n",
      "[2022-12-21 14:12:45,927] Running step: step_apply_folding_config [7/17]\r\n",
      "[2022-12-21 14:12:45,927] Running step: step_generate_estimate_reports [8/17]\r\n",
      "[2022-12-21 14:12:45,928] Running step: step_hls_codegen [9/17]\r\n",
      "[2022-12-21 14:12:51,466] Running step: step_hls_ipgen [10/17]\r\n",
      "[2022-12-21 14:14:44,479] Running step: step_set_fifo_depths [11/17]\r\n"
     ]
    }
   ],
   "source": [
    "! cat ./output_ipstitch_ooc_rtlsim/build_dataflow.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003517c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
