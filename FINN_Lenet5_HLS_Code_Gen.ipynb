{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch a Build: Only Estimate Reports \n",
    "# For Avnet Ultra96-v2 Board, \n",
    "# NN Model: LeNet-5\n",
    "# Dataset: CIFAR-10\n",
    "# This is a modification of \n",
    "# https://github.com/Xilinx/finn/blob/main/notebooks/end2end_example/cybersecurity/3-build-accelerator-with-finn.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9821767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"finn_lenet.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_estimates_only\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 12, #80 was the original but wanted to constrain owidth to multiple of 12 as iwidth = 12\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xczu3eg-sbva484-1-i\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e352a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from finn_lenet.onnx\n",
      "Intermediate outputs will be generated in /home/rstar900/finn/my_builds\n",
      "Final outputs will be generated in output_estimates_only\n",
      "Build log is at output_estimates_only/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/8]\n",
      "Running step: step_tidy_up [2/8]\n",
      "Running step: step_streamline [3/8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rstar900/finn/deps/qonnx/src/qonnx/core/modelwrapper.py:93: UserWarning: Some old-style domain attributes were automatically converted to new-style,\n",
      "                i.e. domain=finn to domain=qonnx.custom_op.<general|fpgadataflow|...>\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step: step_convert_to_hls [4/8]\n",
      "Running step: step_create_dataflow_partition [5/8]\n",
      "Running step: step_target_fps_parallelization [6/8]\n",
      "Running step: step_apply_folding_config [7/8]\n",
      "Running step: step_generate_estimate_reports [8/8]\n",
      "Completed successfully\n",
      "CPU times: user 1.12 s, sys: 0 ns, total: 1.12 s\n",
      "Wall time: 1.12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10bad157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll now examine the generated outputs from this build\n",
    "# If we look under the outputs directory, we'll find a subfolder with the generated estimate reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "517d7845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_folding_config.json  intermediate_models  report  time_per_step.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58a85fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_config_alternatives.json  estimate_network_performance.json\r\n",
      "estimate_layer_cycles.json\t\t op_and_param_counts.json\r\n",
      "estimate_layer_resources.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls {estimates_output_dir}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ed22d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"critical_path_cycles\": 88805,\r\n",
      "  \"max_cycles\": 19760,\r\n",
      "  \"max_cycles_node_name\": \"ConvolutionInputGenerator_0\",\r\n",
      "  \"estimated_throughput_fps\": 5060.728744939272,\r\n",
      "  \"estimated_latency_ns\": 888050.0\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "#  Let's examine the contents of the estimate_network_performance.json for starters. \n",
    "# Here, we can see the analytical estimates for the performance and latency\n",
    "! cat {estimates_output_dir}/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da524668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvolutionInputGenerator_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 372,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_0': {'BRAM_18K': 2,\n",
       "  'BRAM_efficiency': 0.03662109375,\n",
       "  'LUT': 3811,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_Batch_0': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'ConvolutionInputGenerator_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 348,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_1': {'BRAM_18K': 2,\n",
       "  'BRAM_efficiency': 0.1953125,\n",
       "  'LUT': 5254,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'StreamingMaxPool_Batch_1': {'BRAM_18K': 0,\n",
       "  'BRAM_efficiency': 1,\n",
       "  'LUT': 0,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_2': {'BRAM_18K': 12,\n",
       "  'BRAM_efficiency': 0.6510416666666666,\n",
       "  'LUT': 1255,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_3': {'BRAM_18K': 3,\n",
       "  'BRAM_efficiency': 0.546875,\n",
       "  'LUT': 1039,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'MatrixVectorActivation_4': {'BRAM_18K': 1,\n",
       "  'BRAM_efficiency': 0.13671875,\n",
       "  'LUT': 346,\n",
       "  'URAM': 0,\n",
       "  'URAM_efficiency': 1,\n",
       "  'DSP': 0},\n",
       " 'total': {'BRAM_18K': 20.0, 'LUT': 12425.0, 'URAM': 0.0, 'DSP': 0.0}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the layer-by-layer resource estimates in the estimate_layer_resources.json report \n",
    "# We can see if the layers will fit our FPGA using this report, if too high, consider lowering target_fps\n",
    "import json\n",
    "def read_json_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        ret = json.load(f)\n",
    "    return ret\n",
    "\n",
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2741d849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConvolutionInputGenerator_0': 19760,\n",
       " 'MatrixVectorActivation_0': 19600,\n",
       " 'StreamingMaxPool_Batch_0': 980,\n",
       " 'ConvolutionInputGenerator_1': 15420,\n",
       " 'MatrixVectorActivation_1': 10000,\n",
       " 'StreamingMaxPool_Batch_1': 125,\n",
       " 'MatrixVectorActivation_2': 12000,\n",
       " 'MatrixVectorActivation_3': 10080,\n",
       " 'MatrixVectorActivation_4': 840}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at estimate_layer_cycles.json\n",
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_cycles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6014fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfaf4888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.24.0\r\n"
     ]
    }
   ],
   "source": [
    "# Check numpy version (should be 1.22.0)\n",
    "! pip freeze | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c442449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.24.0\n",
      "Uninstalling numpy-1.24.0:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/shutil.py\", line 788, in move\n",
      "    os.rename(src, real_dst)\n",
      "PermissionError: [Errno 13] Permission denied: '/opt/conda/bin/f2py' -> '/tmp/pip-uninstall-cnllz0z7/f2py'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 228, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/commands/uninstall.py\", line 89, in run\n",
      "    uninstall_pathset = req.uninstall(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/req/req_install.py\", line 686, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/req/req_uninstall.py\", line 394, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/req/req_uninstall.py\", line 283, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/pip/_internal/utils/misc.py\", line 352, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/opt/conda/lib/python3.8/shutil.py\", line 803, in move\n",
      "    os.unlink(src)\n",
      "PermissionError: [Errno 13] Permission denied: '/opt/conda/bin/f2py'\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.22.0\n",
      "  Downloading numpy-1.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.22.0\n"
     ]
    }
   ],
   "source": [
    "# if it is not, then run this cell\n",
    "! pip uninstall numpy -y\n",
    "! pip install numpy==1.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e29678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==1.22.0\r\n"
     ]
    }
   ],
   "source": [
    "# Check numpy version again (should be 1.22.0)\n",
    "! pip freeze | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b785e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n"
     ]
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"finn_lenet.onnx\"\n",
    "\n",
    "rtlsim_output_dir = \"output_ipstitch_ooc_rtlsim\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(rtlsim_output_dir):\n",
    "    shutil.rmtree(rtlsim_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "cfg_stitched_ip = build.DataflowBuildConfig(\n",
    "    output_dir          = rtlsim_output_dir,\n",
    "    mvau_wwidth_max     = 12, #80 was the original but wanted to constrain owidth to multiple of 12 as iwidth = 12\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xczu3eg-sbva484-1-i\",\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee1366f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from finn_lenet.onnx\n",
      "Intermediate outputs will be generated in /home/rstar900/finn/my_builds\n",
      "Final outputs will be generated in output_ipstitch_ooc_rtlsim\n",
      "Build log is at output_ipstitch_ooc_rtlsim/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/17]\n",
      "Running step: step_tidy_up [2/17]\n",
      "Running step: step_streamline [3/17]\n",
      "Running step: step_convert_to_hls [4/17]\n",
      "Running step: step_create_dataflow_partition [5/17]\n",
      "Running step: step_target_fps_parallelization [6/17]\n",
      "Running step: step_apply_folding_config [7/17]\n",
      "Running step: step_generate_estimate_reports [8/17]\n",
      "Running step: step_hls_codegen [9/17]\n",
      "Running step: step_hls_ipgen [10/17]\n",
      "Running step: step_set_fifo_depths [11/17]\n",
      "Running step: step_create_stitched_ip [12/17]\n",
      "Running step: step_measure_rtlsim_performance [13/17]\n",
      "Running step: step_out_of_context_synthesis [14/17]\n",
      "Running step: step_synthesize_bitfile [15/17]\n",
      "Running step: step_make_pynq_driver [16/17]\n",
      "Running step: step_deployment_package [17/17]\n",
      "Completed successfully\n",
      "CPU times: user 34.5 s, sys: 230 ms, total: 34.8 s\n",
      "Wall time: 10min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_stitched_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ab7bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_verilog_srcs.txt\t\t       finn_vivado_stitch_proj.xpr\r\n",
      "data\t\t\t\t       ip\r\n",
      "finn_vivado_stitch_proj.cache\t       make_project.sh\r\n",
      "finn_vivado_stitch_proj.gen\t       make_project.tcl\r\n",
      "finn_vivado_stitch_proj.hw\t       vivado.jou\r\n",
      "finn_vivado_stitch_proj.ip_user_files  vivado.log\r\n",
      "finn_vivado_stitch_proj.srcs\r\n"
     ]
    }
   ],
   "source": [
    "# Among the output products, we will find the accelerator exported as a stitched IP block design:\n",
    "! ls {rtlsim_output_dir}/stitched_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "003517c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate_layer_resources_hls.json  rtlsim_performance.json\r\n",
      "ooc_synth_and_timing.json\r\n"
     ]
    }
   ],
   "source": [
    "# We also have a few reports generated by these output products, different from the ones generated by ESTIMATE_REPORTS.\n",
    "! ls {rtlsim_output_dir}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2273ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"vivado_proj_folder\": \"/home/rstar900/finn/my_builds/synth_out_of_context_j_hy7xco/results_finn_design_wrapper\",\r\n",
      "  \"LUT\": 8591.0,\r\n",
      "  \"LUTRAM\": 644.0,\r\n",
      "  \"FF\": 7921.0,\r\n",
      "  \"DSP\": 0.0,\r\n",
      "  \"BRAM\": 10.0,\r\n",
      "  \"BRAM_18K\": 4.0,\r\n",
      "  \"BRAM_36K\": 8.0,\r\n",
      "  \"URAM\": 0.0,\r\n",
      "  \"Carry\": 413.0,\r\n",
      "  \"WNS\": 4.2,\r\n",
      "  \"Delay\": 4.2,\r\n",
      "  \"vivado_version\": 2022.1,\r\n",
      "  \"vivado_build_no\": 3526262.0,\r\n",
      "  \"\": 0,\r\n",
      "  \"fmax_mhz\": 172.41379310344828,\r\n",
      "  \"estimated_throughput_fps\": 8725.394387826329\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "# In ooc_synth_and_timing.json we can find the post-synthesis and maximum clock frequency estimate for the accelerator. \n",
    "# Note that the clock frequency estimate here tends to be optimistic, since out-of-context synthesis is less constrained.\n",
    "! cat {rtlsim_output_dir}/report/ooc_synth_and_timing.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2f3cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"cycles\": 46299,\r\n",
      "  \"runtime[ms]\": 0.46299,\r\n",
      "  \"throughput[images/s]\": 2159.8738633663793,\r\n",
      "  \"DRAM_in_bandwidth[MB/s]\": 3.3175662541307585,\r\n",
      "  \"DRAM_out_bandwidth[MB/s]\": 0.04319747726732758,\r\n",
      "  \"fclk[mhz]\": 100.0,\r\n",
      "  \"N\": 1,\r\n",
      "  \"latency_cycles\": 46299\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "# in rtlsim_performance.json we can find the steady-state throughput and latency for the accelerator, as obtained by rtlsim. \n",
    "# If the DRAM bandwidth numbers reported here are below what the hardware platform is capable of \n",
    "# (i.e. the accelerator is not memory-bound), \n",
    "# you can expect the same steady-state throughput (excluding any software/driver overheads) in real hardware.\n",
    "\n",
    "! cat {rtlsim_output_dir}/report/rtlsim_performance.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "122652a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"Defaults\": {},\r\n",
      "  \"StreamingFIFO_0\": {\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"depth\": 256,\r\n",
      "    \"impl_style\": \"rtl\"\r\n",
      "  },\r\n",
      "  \"ConvolutionInputGenerator_0\": {\r\n",
      "    \"SIMD\": 3,\r\n",
      "    \"ram_style\": \"distributed\"\r\n",
      "  },\r\n",
      "  \"MatrixVectorActivation_0\": {\r\n",
      "    \"PE\": 6,\r\n",
      "    \"SIMD\": 3,\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"resType\": \"lut\",\r\n",
      "    \"mem_mode\": \"decoupled\",\r\n",
      "    \"runtime_writeable_weights\": 0\r\n",
      "  },\r\n",
      "  \"StreamingMaxPool_Batch_0\": {\r\n",
      "    \"PE\": 1\r\n",
      "  },\r\n",
      "  \"StreamingFIFO_3\": {\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"depth\": 32,\r\n",
      "    \"impl_style\": \"rtl\"\r\n",
      "  },\r\n",
      "  \"StreamingDataWidthConverter_Batch_0\": {\r\n",
      "    \"impl_style\": \"hls\"\r\n",
      "  },\r\n",
      "  \"StreamingFIFO_4\": {\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"depth\": 256,\r\n",
      "    \"impl_style\": \"rtl\"\r\n",
      "  },\r\n",
      "  \"ConvolutionInputGenerator_1\": {\r\n",
      "    \"SIMD\": 1,\r\n",
      "    \"ram_style\": \"distributed\"\r\n",
      "  },\r\n",
      "  \"StreamingDataWidthConverter_Batch_1\": {\r\n",
      "    \"impl_style\": \"hls\"\r\n",
      "  },\r\n",
      "  \"StreamingFIFO_6\": {\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"depth\": 32,\r\n",
      "    \"impl_style\": \"rtl\"\r\n",
      "  },\r\n",
      "  \"MatrixVectorActivation_1\": {\r\n",
      "    \"PE\": 8,\r\n",
      "    \"SIMD\": 3,\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"resType\": \"lut\",\r\n",
      "    \"mem_mode\": \"decoupled\",\r\n",
      "    \"runtime_writeable_weights\": 0\r\n",
      "  },\r\n",
      "  \"StreamingDataWidthConverter_Batch_2\": {\r\n",
      "    \"impl_style\": \"hls\"\r\n",
      "  },\r\n",
      "  \"StreamingMaxPool_Batch_1\": {\r\n",
      "    \"PE\": 1\r\n",
      "  },\r\n",
      "  \"StreamingDataWidthConverter_Batch_3\": {\r\n",
      "    \"impl_style\": \"hls\"\r\n",
      "  },\r\n",
      "  \"StreamingFIFO_10\": {\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"depth\": 64,\r\n",
      "    \"impl_style\": \"rtl\"\r\n",
      "  },\r\n",
      "  \"MatrixVectorActivation_2\": {\r\n",
      "    \"PE\": 1,\r\n",
      "    \"SIMD\": 4,\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"resType\": \"lut\",\r\n",
      "    \"mem_mode\": \"decoupled\",\r\n",
      "    \"runtime_writeable_weights\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFIFO_11\": {\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"depth\": 32,\r\n",
      "    \"impl_style\": \"rtl\"\r\n",
      "  },\r\n",
      "  \"MatrixVectorActivation_3\": {\r\n",
      "    \"PE\": 1,\r\n",
      "    \"SIMD\": 1,\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"resType\": \"lut\",\r\n",
      "    \"mem_mode\": \"decoupled\",\r\n",
      "    \"runtime_writeable_weights\": 0\r\n",
      "  },\r\n",
      "  \"MatrixVectorActivation_4\": {\r\n",
      "    \"PE\": 1,\r\n",
      "    \"SIMD\": 1,\r\n",
      "    \"ram_style\": \"auto\",\r\n",
      "    \"resType\": \"lut\",\r\n",
      "    \"mem_mode\": \"decoupled\",\r\n",
      "    \"runtime_writeable_weights\": 0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Finally, let's have a look at final_hw_config.json. \n",
    "# This is the node-by-node hardware configuration determined by the FINN compiler, \n",
    "# including FIFO depths, parallelization settings (PE/SIMD) and others. \n",
    "# If you want to optimize your build further (the \"advanced\" method we mentioned under \"Configuring the performance\"), \n",
    "# you can use this .json file as the folding_config_file \n",
    "# for a new run to use it as a starting point for further exploration and optimizations.\n",
    "\n",
    "! cat {rtlsim_output_dir}/final_hw_config.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
